# What is NLP?

Natural Language Processing (NLP) is one of areas in data science that specialises in understanding spoken and written word. It's a subset of linguistics as well as computer science and revolves around transforming language in a way that computers can understand and later analyse. NLP is currently peaking on its popularity because of what kind of services can be built with it. We're talking chatbots, recommendation systems, sentiment analysis, speech recognition and much more.

It might seem like a very recent technology, but it's actually a bit older than we assume. The study of language processing started in 1950s, but we can find some studies from even earlier periods in the history. From 1906 to 1911, Professor Saussure offered three courses at the University of Geneva, where he developed an approach describing languages as â€œsystems" and later, in 1950 Turing published a paper that talked about a possibility of machines communicating with humans.

Nowadays, it's a part of science that finds its used in almost any business, finance, IT or even your local grocery stores. Language can be found everywhere, analysing it can bring a lot of value to the way services communicate with customers but also our understanding of what they want or enjoy.

There is obviously some limitations and challenges that data scientists face when working on data like that, some of them include contextual words/synonyms in text, irony, ambiguity or domain specific language.



## Real life examples

### 1) Siri, Alexa, or Google Assistant

All of these three, and probably any kind of accurate virtual assistant has some NLP involved. They have to process spoken language, understand what you meant and return the best possible answer. In Google Assistant's case they recently announced [[1]](https://www.blog.google/products/search/search-language-understanding-bert/) a new way of processing the language that they have been working on called BERT (Bidirectional Encoder Representations from Transformers) that focuses on building question answering systems.



### 2) Labelling Books (CommonLit Competition)

CommonLit, Inc., is a non-profit education technology organization serving over 20 million teachers and students with free digital reading and writing lessons for grades 3-12. They came together with the Georgia State University to create a Kaggle competition that has its goal in improving classification of text for students. Using NLP contestants create models that distinguish between readability levels.



### 3) Grammarly

Grammar assistant used by many, including me. It helps people write more accurate texts by detecting its tone, providing suggestions for better word fits and much more. It's a software that comes in many different forms, mainly as a browser plugin and makes sure that everything is spelled well in your email and its inside doesn't sound too fun when you write to someone important.



## Useful papers and articles

In this document, I would also like to provide links to some very useful articles if you're only getting into the topic. I, myself, don't have much experience with it but seeing the possibilities it provides, it only makes sense to get more familiar with it. Some of them require previous knowledge.

- [Language Models are Unsupervised Multitask Learners by Alec Radford, et al.](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova](https://arxiv.org/pdf/1810.04805.pdf)
- [List of interesting NLP papers by @gyunggyung](https://github.com/gyunggyung/NLP-Papers)

